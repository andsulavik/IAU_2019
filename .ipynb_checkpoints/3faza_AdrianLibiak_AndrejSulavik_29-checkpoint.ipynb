{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import linear_model\n",
    "\n",
    "import re\n",
    "\n",
    "percentil5 = []\n",
    "percentil95 = []\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='median')\n",
    "\n",
    "linearKurtOx = linear_model.LinearRegression()\n",
    "linearMeanGlu = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitPersonalInfo(dataO):\n",
    "    temp = dataO['personal_info'].str.split(\"\\r\\r\\n|\\r\\n|--|\\\\|\", expand = True)\n",
    "    dataO['ethn'] = temp[0]\n",
    "    dataO['state'] = temp[1]\n",
    "    dataO['edu'] = temp[2]\n",
    "    dataO['status'] = temp[3]\n",
    "    dataO['fam_memb'] = temp[4] \n",
    "    dataO.drop(['personal_info'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionDuplicates(datasetO):\n",
    "    duplicat = datasetO[datasetO['name'].duplicated(keep=False)]\n",
    "    duplicat = duplicat.sort_values('name')\n",
    "    duplicat = duplicat.reset_index(drop=True)\n",
    "    \n",
    "    position = 0\n",
    "    \n",
    "    for i, row in duplicat.iterrows():\n",
    "        if(row['name']==duplicat.loc[position,'name'] and i!=0):\n",
    "            for j, value in row.items():\n",
    "                dupValue = duplicat.loc[position,j]\n",
    "                if(pd.isna(dupValue)):\n",
    "                    duplicat.loc[position,j]=value\n",
    "            duplicat = duplicat.drop(i)\n",
    "        else:\n",
    "            position = i\n",
    "        \n",
    "    datasetO.drop_duplicates(subset='name',keep=False,inplace=True)\n",
    "    result = datasetO.append(duplicat, ignore_index=True)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctValuesO(dataset):\n",
    "    for col in dataset.columns:\n",
    "        if(dataset[col].dtype != np.object):\n",
    "            continue\n",
    "        dataset[col] = dataset[col].str.replace('_','-')\n",
    "        dataset[col] = dataset[col].replace(to_replace = r'.*\\?.*', value = np.nan, regex = True)\n",
    "        dataset[col] = dataset[col].replace(to_replace = r'^[Nn][Aa][Nn]$', value = np.nan, regex = True)\n",
    "        if(col=='pregnant'):\n",
    "            dataset[col] = dataset[col].replace(['T','F'], ['t', 'f'])\n",
    "            dataset[col] = dataset[col].replace(to_replace = r'[Tt][Rr][Uu][Ee]', value = 't', regex = True)\n",
    "            dataset[col] = dataset[col].replace(to_replace = r'[Ff][Aa][Ll][Ss][Ee]', value = 'f', regex = True)\n",
    "\n",
    "def correctDates(series):\n",
    "    s = series.str.split(\"-\", expand = True)\n",
    "    x = 0\n",
    "    while(x<len(series)):\n",
    "#        print(str(x)+\" \"+s.iloc[x])\n",
    "        if(re.match(r'^[0-9][0-9]-[0-9][0-9]-[0-9][0-9]$', series.loc[x])):\n",
    "            if(s.iloc[x][0][:1]=='0'):\n",
    "                series.loc[x] = \"20\"+s.iloc[x][0]+\"-\"+s.iloc[x][1]+\"-\"+s.iloc[x][2][0:2]\n",
    "            else:\n",
    "                series.loc[x] = \"19\"+s.iloc[x][0]+\"-\"+s.iloc[x][1]+\"-\"+s.iloc[x][2][0:2]\n",
    "#            x += 1\n",
    "#            continue\n",
    "         #if(len(s.iloc[x][2])>2):\n",
    "         #   series.loc[x] = s.iloc[x][0]+\"-\"+s.iloc[x][1]+\"-\"+s.iloc[x][2][:2]\n",
    "        if(re.match(r'^[0-9][0-9]-[0-9][0-9]-[0-9][0-9][0-9][0-9]$', series.loc[x])):\n",
    "            y = s.iloc[x][0]\n",
    "            s.iloc[x][0] = s.iloc[x][2]\n",
    "            s.iloc[x][2] = y\n",
    "            series.loc[x] = s.iloc[x][0]+\"-\"+s.iloc[x][1]+\"-\"+s.iloc[x][2][0:2]\n",
    "        if(len(series.loc[x])>10):\n",
    "            series.loc[x] = series.loc[x][0:10]\n",
    "        x += 1\n",
    "        \n",
    "def correctValuesP(dataset):\n",
    "    for col in dataset.columns:\n",
    "        if(dataset[col].dtype != np.object):\n",
    "            continue\n",
    "        dataset[col] = dataset[col].str.replace('/','-')    \n",
    "    correctDates(dataset[\"date_of_birth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusionDatasets(dataset1, dataset2):\n",
    "    newDS = dataset1.merge(dataset2, on='name')\n",
    "    newDS = newDS.drop(columns=['name', 'address_x', 'address_y'])\n",
    "    return newDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctAge(dataF):\n",
    "    x = 0\n",
    "    for x in range(len(dataF)):\n",
    "        #print(x)\n",
    "        s = dataF['date_of_birth'].iloc[x].split('-', 2)\n",
    "        year = s[0]\n",
    "        #116 najstarsi clovek v sucastnosti\n",
    "        if(dataF['age'].iloc[x]>116):\n",
    "            age = dataF['age'].iloc[x]/100\n",
    "            if((2019-int(age) == int(year) or (2019-int(age) == int(year)+1))):\n",
    "                dataF['age'].iloc[x] =  int(age);\n",
    "                continue\n",
    "            else:\n",
    "                print(\"ERROR  \"+str(age)+\"  \"+str(int(year)))\n",
    "        elif(dataF['age'].iloc[x]<-116):\n",
    "            age = dataF['age'].iloc[x]/(-100)\n",
    "            if(2019-int(age) == int(year) or 2019-int(age) == int(year)+1):\n",
    "                dataF['age'].iloc[x] =  int(age);\n",
    "                continue\n",
    "            else:\n",
    "                print(\"ERROR  \"+str(age)+\"  \"+str(int(year)))\n",
    "        else:\n",
    "            age = 2019 - int(year)\n",
    "            if(age<=0):\n",
    "                dataF['age'].iloc[x] = np.nan\n",
    "            else:\n",
    "                dataF['age'].iloc[x] =  int(age);\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectReplaceOutliers(dataF):\n",
    "    for col in dataF.columns:\n",
    "        if(dataF[col].dtype == np.object):\n",
    "            continue\n",
    "        if(col == 'capital-loss' or col == 'capital-gain' or col == 'age'):\n",
    "            continue\n",
    "        if(col != 'std_glucose' and col != 'fnlwgt' and col != 'mean_glucose' and col != 'hours-per-week'):\n",
    "            dataF.loc[:,col] = dataF[col].apply(lambda x: -2.5 if x<-2.5 else x)\n",
    "            dataF.loc[:,col] = pd.Series(np.log(dataF[col]+2.5))\n",
    "        percentil5.append(dataF[col].quantile(0.05))\n",
    "        percentil95.append(dataF[col].quantile(0.95))\n",
    "        p5 = percentil5[-1]\n",
    "        p95 = percentil95[-1]\n",
    "        print(col+\" q0.05: \"+str(p5))\n",
    "        print(col+\" q0.95: \"+str(p95))\n",
    "        dataF.loc[:,col] = dataF[col].apply(lambda x: p5 if x<p5 else x)\n",
    "        dataF.loc[:,col] = dataF[col].apply(lambda x: p95 if x>p95 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformDetectReplaceOutliers(dataF):\n",
    "    i = 0\n",
    "    for col in dataF.columns:\n",
    "        if(dataF[col].dtype == np.object):\n",
    "            continue\n",
    "        if(col == 'capital-loss' or col == 'capital-gain' or col == 'age'):\n",
    "            continue\n",
    "        if(col != 'std_glucose' and col != 'fnlwgt' and col != 'mean_glucose' and col != 'hours-per-week'):\n",
    "            dataF.loc[:,col] = dataF[col].apply(lambda x: -2.5 if x<-2.5 else x)\n",
    "            dataF.loc[:,col] = pd.Series(np.log(dataF[col]+2.5))\n",
    "        p5 = percentil5[i]\n",
    "        p95 = percentil95[i]\n",
    "        i=i+1\n",
    "        dataF.loc[:,col] = dataF[col].apply(lambda x: p5 if x<p5 else x)\n",
    "        dataF.loc[:,col] = dataF[col].apply(lambda x: p95 if x>p95 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impMedianFit(dataF):\n",
    "    imp.fit(dataF[[\"age\",\"skewness_glucose\",\"std_oxygen\", \"capital-gain\", \"skewness_oxygen\", \"kurtosis_glucose\", \"fnlwgt\", \"std_glucose\", \"mean_oxygen\", \"hours-per-week\", \"capital-loss\"]])\n",
    "    \n",
    "def impMedianTransform(dataF):\n",
    "    dataF[[\"age\",\"skewness_glucose\",\"std_oxygen\", \"capital-gain\", \"skewness_oxygen\", \"kurtosis_glucose\", \"fnlwgt\", \"std_glucose\", \"mean_oxygen\", \"hours-per-week\", \"capital-loss\"]] = imp.transform(dataF[[\"age\",\"skewness_glucose\",\"std_oxygen\", \"capital-gain\", \"skewness_oxygen\", \"kurtosis_glucose\", \"fnlwgt\", \"std_glucose\", \"mean_oxygen\", \"hours-per-week\", \"capital-loss\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearFit(dataF):\n",
    "    dataToFit = dataF[~dataF[\"kurtosis_oxygen\"].isnull()]\n",
    "    linearKurtOx.fit(X = dataToFit[[\"skewness_oxygen\",\"mean_oxygen\"]], y = dataF[\"kurtosis_oxygen\"].dropna())\n",
    "    dataToFit = dataF[~dataF[\"mean_glucose\"].isnull()]\n",
    "    linearMeanGlu.fit(X = dataToFit[[\"skewness_glucose\", \"kurtosis_glucose\"]], y = dataF[\"mean_glucose\"].dropna())\n",
    "def linearTransform(dataF):\n",
    "    dataF.loc[dataF[\"kurtosis_oxygen\"].isnull(), \"kurtosis_oxygen\"] = linearKurtOx.predict(dataF[[\"skewness_oxygen\",\"mean_oxygen\"]])[dataF[\"kurtosis_oxygen\"].isnull()]\n",
    "    dataF.loc[dataF[\"mean_glucose\"].isnull(), \"mean_glucose\"] = linearMeanGlu.predict(dataF[[\"skewness_glucose\", \"kurtosis_glucose\"]])[dataF[\"mean_glucose\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setKategNaNtoUnknown(dataF):\n",
    "    for col in dataF.columns:\n",
    "        if(dataF[col].dtype != np.object):\n",
    "            continue\n",
    "        dataF[col].replace(to_replace=np.nan, value='unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalFitAndTransform(dataP,dataO):\n",
    "    print('spliting personal info')\n",
    "    splitPersonalInfo(dataO)\n",
    "    print('deduplicating names')\n",
    "    dataO=fusionDuplicates(dataO)\n",
    "    print('correcting O values')\n",
    "    correctValuesO(dataO)\n",
    "    print('correcting P values')\n",
    "    correctValuesP(dataP)\n",
    "    print('merging datasets')\n",
    "    dataF = fusionDatasets(dataP, dataO)\n",
    "    if('class'in dataF.columns):\n",
    "        dataF = dataF.astype({'class':str,\"education-num\":str,\"kurtosis_oxygen\":float})\n",
    "    else:\n",
    "        dataF = dataF.astype({\"education-num\":str,\"kurtosis_oxygen\":float})\n",
    "    \n",
    "    print('correcting age')\n",
    "    correctAge(dataF)\n",
    "    print('correcting outliers')\n",
    "    detectReplaceOutliers(dataF)\n",
    "    \n",
    "    setKategNaNtoUnknown(dataF)\n",
    "    print('filling missing values with median')\n",
    "    impMedianFit(dataF)\n",
    "    impMedianTransform(dataF)\n",
    "    print('filling missing values with linear regression')\n",
    "    linearFit(dataF)\n",
    "    linearTransform(dataF)\n",
    "    return dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalTransform(dataP,dataO):\n",
    "    print('correcting values')\n",
    "    splitPersonalInfo(dataO)\n",
    "    dataO=fusionDuplicates(dataO)\n",
    "    correctValuesO(dataO)\n",
    "    correctValuesP(dataP)\n",
    "    dataF = fusionDatasets(dataP, dataO)\n",
    "    if('class'in dataF.columns):\n",
    "        dataF = dataF.astype({'class':str,\"education-num\":str,\"kurtosis_oxygen\":float})\n",
    "    else:\n",
    "        dataF = dataF.astype({\"education-num\":str,\"kurtosis_oxygen\":float})\n",
    "    print('working with outliers')\n",
    "    correctAge(dataF)\n",
    "    transformDetectReplaceOutliers(dataF)\n",
    "    print('filling missing values')\n",
    "    setKategNaNtoUnknown(dataF)\n",
    "    impMedianTransform(dataF)\n",
    "    linearTransform(dataF)\n",
    "    return dataF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predspracovanie z minulej fázy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainP = pd.read_csv(\"personal_train.csv\", index_col=0)\n",
    "trainO = pd.read_csv(\"other_train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validP = pd.read_csv(\"personal_valid.csv\", index_col=0)\n",
    "validO = pd.read_csv(\"other_valid.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testP = pd.read_csv(\"personal_test.csv\", index_col=0)\n",
    "testO = pd.read_csv(\"other_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Spustenie predspracovaia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = finalFitAndTransform(trainP,trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = finalTransform(validP,validO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = finalTransform(testP,testO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutné úpravy v predspracovaní pre test.csv:<br>\n",
    "V splitovaní personal info bolo potrebné pridať oddelovač \"\\r\\n\"<br>\n",
    "Deduplikacia uprevanená pre hocijaký počet duplikátov nie len 2<br>\n",
    "Pridanie podmienky ak sa stĺpec class nenachádza v datasete nepracuj s ním<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Manuálne vytvorenie a vyhodnotenie rozhodovacích pravidiel pre klasifikáciu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train,x_vars=[\"skewness_glucose\", \"kurtosis_glucose\",\"mean_oxygen\"],y_vars=[\"skewness_glucose\", \"kurtosis_glucose\",\"mean_oxygen\"],hue = 'class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na základe analýzy sme vybrali pre manuálne rozhodovanie tieto tri atribúty a pre rozhodovanie na základe jedného atribútu sme zvolili kurtosis_glucose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualDecisionTree(row):\n",
    "        if(row[\"kurtosis_glucose\"]<1.3):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0\n",
    "\n",
    "def manualDecisionTreeMultiple(row):\n",
    "        if(row[\"skewness_glucose\"]<1.8 and row[\"kurtosis_glucose\"]<1.3 and row[\"mean_oxygen\"]<2.3):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1atribut = valid.apply(lambda row: manualDecisionTree(row), axis=1)\n",
    "prediction3atributes = valid.apply(lambda row: manualDecisionTreeMultiple(row), axis=1)\n",
    "classs = valid[\"class\"].astype({'class':float})\n",
    "accuracy_score(classs,prediction1atribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(classs,prediction3atributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(classs,prediction1atribut, pos_label=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(classs,prediction3atributes, pos_label=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(classs,prediction1atribut, pos_label=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(classs,prediction3atributes, pos_label=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naše manuálne klasifikátory sme vyhodnotili na validačných dátach. Jednoduchý klasifikátor má správnosť 0.95, presnosť 0.97 a úplnosť 0.85.<br>Zložitejší klasifikátor má správnosť 0.87, presnosť 0.68 a úplnosť 0.93.<br>Zložitejší klasifikátor má lepšiu len úplnosť."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Natrénovanie a vyhodnotenie klasifikátora s využitím rozhodovacích stromov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decTree = DecisionTreeClassifier()\n",
    "model = decTree.fit(train.select_dtypes(exclude=['object']), train[\"class\"])\n",
    "\n",
    "decTree.score(train.select_dtypes(exclude=['object']), train[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(valid.select_dtypes(exclude=['object']))\n",
    "accuracy_score(valid[\"class\"], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(valid[\"class\"], prediction, pos_label='1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(valid[\"class\"], prediction, pos_label='1.0')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Správnosť tohto stromu je približne rovnaká ako našho klasifikátora s jedným atribútom. Presnosť je horšia ako jednoduchého, ale omnoho lepšia ako zložitejšieho a úplnosť je rovnaká ako našho zložitejšieho klasifikátora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimalizácia hyperparametrov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(decTree,train.select_dtypes(exclude=['object']),train[\"class\"],cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Vyhodnotenie vplyvu zvolenej stratégie riešenia chýbajúcich hodnôt na správnosť klasifikácie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
